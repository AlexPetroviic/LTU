{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec6c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "\n",
    "files = [\n",
    "    data_dir/\"Trail1_extracted.csv\",\n",
    "    data_dir/\"Trail2_extracted.csv\",\n",
    "    data_dir/\"Trail3_extracted.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff27e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hittade filer:\n",
      "/home/alex/Documents/LTU/ltu-assignments/Assignment-3/data/Trail1_extracted.csv\n",
      "/home/alex/Documents/LTU/ltu-assignments/Assignment-3/data/Trail2_extracted.csv\n",
      "/home/alex/Documents/LTU/ltu-assignments/Assignment-3/data/Trail3_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Hittade filer:\")\n",
    "for file in files:\n",
    "    if(file.is_file()):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e01220c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 22)\n",
      "Index(['mean', 'std', 'max', 'min', 'range', 'skewness', 'kurtosis', 'rms',\n",
      "       'crest_factor', 'variance', 'zero_crossings', 'dominant_freq',\n",
      "       'spectral_energy', 'spectral_centroid', 'spectral_bandwidth',\n",
      "       'spectral_flatness', 'start_time', 'event', 'axle', 'cluster', 'tsne_1',\n",
      "       'tsne_2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dfs = [pd.read_csv(f) for f in files] #läs in csv filerna i dfs\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bc2ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_time', 'axle', 'cluster', 'tsne_1', 'tsne_2']\n",
      "Dessa kolumner togs bort:  ['start_time', 'axle', 'cluster', 'tsne_1', 'tsne_2']\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['start_time', 'axle', 'cluster', 'tsne_1', 'tsne_2']\n",
    "print(drop_cols)\n",
    "\n",
    "drop_cols_list = [] #skapar en ny lista\n",
    "for c in drop_cols:\n",
    "    if c in df.columns: #om c finns i drop_list\n",
    "        drop_cols_list.append(c) #så läggs den till här OM den finns\n",
    "drop_cols = drop_cols_list #Sedan gör jag om drop_cols till min lista efter jag verifierat att de kolumnerna finns.\n",
    "\n",
    "df = df.drop(columns=drop_cols_list)\n",
    "print(\"Dessa kolumner togs bort: \", drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9994bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_col = df[\"event\"] #skapar ny var från df[event] col\n",
    "\n",
    "event_col = event_col.astype(str) #gör alla cols till string\n",
    "event_col = event_col.str.strip() #tar bort spaces före och efter värdet\n",
    "event_col = event_col.str.lower() #gör allt till små bokstäver\n",
    "\n",
    "df[\"event\"] = event_col #uppdatera col event med ändringarna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9e07929",
   "metadata": {},
   "outputs": [],
   "source": [
    "bv = []\n",
    "\n",
    "for val in df['event']:\n",
    "    if(val == \"normal\"):\n",
    "        bv.append(0)\n",
    "    else:\n",
    "        bv.append(1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec19b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event\n",
      "normal      60\n",
      "joint x      6\n",
      "squat a      6\n",
      "squat b      6\n",
      "squat c      6\n",
      "squat d      6\n",
      "squat e      6\n",
      "squat f      6\n",
      "squat g      6\n",
      "squat h      6\n",
      "crossing     6\n",
      "squat i      6\n",
      "squat j      6\n",
      "joint y      6\n",
      "joint z      6\n",
      "squat k      6\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "event\n",
      "1    90\n",
      "0    60\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['event'].value_counts(), '\\n')\n",
    "df['event'] = bv\n",
    "print(df['event'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "070a7730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 16 features exists\n"
     ]
    }
   ],
   "source": [
    "FEATURES = [\n",
    "    \"mean\",\"std\",\"max\",\"min\",\"range\",\"skewness\",\"kurtosis\",\"rms\",\n",
    "    \"crest_factor\",\"variance\",\"zero_crossings\",\n",
    "    \"dominant_freq\",\"spectral_energy\",\"spectral_centroid\",\"spectral_bandwidth\",\"spectral_flatness\"\n",
    "]\n",
    "\n",
    "missing = [mc for mc in FEATURES if mc not in df.columns]\n",
    "if(len(missing)== 0):\n",
    "    print(\"All 16 features exists\")\n",
    "else:\n",
    "    print(\"These features are missing: \", missing)\n",
    "    \n",
    "#kopierar df[FEATURES]\n",
    "#och df[event]\n",
    "#så att ändringar inte påverkar orginalet\n",
    "x = df[FEATURES].copy()\n",
    "y = df[\"event\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0154ba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preppad fil skapad: data/rail_preprocessed.csv\n",
      "Preppad fil skapad: data/rail_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Skala\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[FEATURES])\n",
    "\n",
    "# Se till att katalogen 'data' finns\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) Bygg preppad DataFrame och spara\n",
    "df_prepped = pd.DataFrame(X_scaled, columns=FEATURES)\n",
    "df_prepped[\"event\"] = df[\"event\"].values\n",
    "df_prepped.to_csv(\"data/rail_preprocessed.csv\", index=False)\n",
    "\n",
    "print(\"Preppad fil skapad:\", \"data/rail_preprocessed.csv\")\n",
    "\n",
    "df_prepped = pd.DataFrame(X_scaled, columns=FEATURES)\n",
    "df_prepped[\"event\"] = df[\"event\"].values\n",
    "df_prepped.to_csv(\"data/rail_preprocessed.csv\", index=False)\n",
    "\n",
    "print(\"Preppad fil skapad:\", \"data/rail_preprocessed.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
